# 书生浦语大模型

> #### 模型
>
> > 专用模型：
> >
> > 针对特定任务，一个模型解决一个问题
> >
> > 通用大模型：
> >
> > 一个模型应对多种任务，多种模态
>
> ####  InternLM2的三种模型：
>
> > InternLM2-Base
> >
> > InternLM2(给予base多方向强化)
> >
> > InternLM2-Chat(基于base, 经过SFT和RLHF,面向对话交互进行了优化)
>
> #### 书生浦语2.0的主要亮点：
>
> * 超长上下文
> * 综合性能全面提升
> * 优秀的对话和创作体验
> * 工具调用能力整体升级
> * 突出的数理能力和实用的数据分析功能
>
> #### 书生浦语的应用：
>
> * 智能客服
> * 个人助手
> * 行业应用
>
> #### 从模型到应用的典型流程：
>
> ![](./a1.png)
>
> 1. 模型选型
>
> 2. 业务常见是否复杂？
>
>    复杂 ----> 进行微调, 算力足够---->续训/全参数微调
>
>    算力不够---->部分参数微调
>
> 3. 微调之后, 是否需要与环境交互？
>
>    需要，就构建智能体
>
>    不需要
>
> 4. 模型评测
>
> 5. 模型部署
>
>    
>
>    ![](./a2.png)
>
> * 书生万卷数据集
>
> * 预训练
>
>   ![](a3.png)
>
>   
>
> * 微调
>
>   ![](a4.png)
>
>   ![](a5.png)
>
>   
>
> * 部署
>
>   ![](a6.png)
>
> * 评测
>
>   
>
> * 应用
>
> 
>
> 智能体：
>
> ![](a7.png)
>
> ![](a8.png)

